{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "9e64bf46",
   "metadata": {},
   "outputs": [],
   "source": [
    "import operator\n",
    "from typing import Annotated, TypedDict\n",
    "from langchain_community.chat_models import ChatOllama\n",
    "from langgraph.graph import StateGraph, END\n",
    "from IPython.display import display, Markdown"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "33b92aaa",
   "metadata": {},
   "source": [
    "# --- 1. Define the Graph State ---\n",
    "- This defines the \"schema\" of the state that will be passed between nodes."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "d81baa5d",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "class GraphState(TypedDict):\n",
    "    \"\"\"\n",
    "    Represents the state of our graph.\n",
    "\n",
    "    Attributes:\n",
    "        question: The user's initial question.\n",
    "        response: The accumulated response from the LLMs.\n",
    "    \"\"\"\n",
    "    question: str\n",
    "    response: Annotated[str, operator.add] # Use operator.add to append responses"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "29526012",
   "metadata": {},
   "outputs": [],
   "source": [
    "# --- 2. Initialize Local LLMs ---\n",
    "# Assuming you have Ollama running and these models downloaded:\n",
    "# ollama run llama3:8b\n",
    "\n",
    "try:\n",
    "    llm_1 = ChatOllama(model=\"qwen3:0.6b\", temperature=0) # Often a good general-purpose lightweight model\n",
    "    llm_2 = ChatOllama(model=\"qwen3:0.6b\", temperature=0) # Another popular lightweight choice\n",
    "    llm_3 = ChatOllama(model=\"qwen3:0.6b\", temperature=0) # Very small, good for basic tasks\n",
    "except Exception as e:\n",
    "    print(f\"Error initializing Ollama models. Make sure Ollama is running and models are downloaded.\")\n",
    "    print(f\"You can download models with: ollama run qwen3:0.6b\")\n",
    "    print(f\"Error: {e}\")\n",
    "    exit()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "0d788ebf",
   "metadata": {},
   "outputs": [],
   "source": [
    "# --- 3. Define Nodes (Functions for each LLM) ---\n",
    "\n",
    "def llm_node_1(state: GraphState):\n",
    "    \"\"\"\n",
    "    First LLM processing node.\n",
    "    \"\"\"\n",
    "    print(\"---NODE 1: Llama3 Processing---\")\n",
    "    question = state[\"question\"]\n",
    "    # Simulate some processing by the LLM\n",
    "    llm_response = llm_1.invoke(f\"\"\"Process this: {question}. Add a brief introduction. \n",
    "                                Start your final response with text **'Response 1:'** \"\"\")\n",
    "    \n",
    "    return {\"response\": f\"Node 1 Qwen's take: {llm_response.content}\\n\"}\n",
    "\n",
    "def llm_node_2(state: GraphState):\n",
    "    \"\"\"\n",
    "    Second LLM processing node.\n",
    "    \"\"\"\n",
    "    print(\"---NODE 2: Mistral Processing---\")\n",
    "    question = state[\"question\"]\n",
    "    current_response = state.get(\"response\", \"\")\n",
    "    #current_response = current_response.split(\"Response 1:\")[-1]\n",
    "    # Simulate more processing based on the question and previous response\n",
    "    llm_response = llm_2.invoke(f\"\"\"Elaborate on: '{question}'. Consider previous output: '{current_response}' \n",
    "                                Start your final response with text **'Response 2:'** \"\"\")\n",
    "\n",
    "    return {\"response\": f\"Node 2 Qwen's take: {llm_response.content}\\n\"}\n",
    "\n",
    "\n",
    "def llm_node_3(state: GraphState):\n",
    "    \"\"\"\n",
    "    Third LLM processing node.\n",
    "    \"\"\"\n",
    "    print(\"---NODE 3: TinyLlama Processing---\")\n",
    "    question = state[\"question\"]\n",
    "    current_response = state.get(\"response\", \"\")\n",
    "    # Simulate a final touch or summary\n",
    "    llm_response = llm_3.invoke(f\"\"\"Summarize the main point of '{question}' after seeing this: '{current_response}'.\n",
    "                                Start your final response with text **'Response 3:'** \"\"\")\n",
    "\n",
    "    return {\"response\": f\"Llama3's take: {llm_response.content}\\n\"}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "df03a8bf",
   "metadata": {},
   "outputs": [],
   "source": [
    "# --- 4. Build the LangGraph Workflow ---\n",
    "\n",
    "workflow = StateGraph(GraphState)\n",
    "\n",
    "# Add nodes to the workflow\n",
    "workflow.add_node(\"QwenNode1\", llm_node_1)\n",
    "workflow.add_node(\"QwenNode2\", llm_node_2)\n",
    "workflow.add_node(\"QwenNode3\", llm_node_3)\n",
    "\n",
    "# Define the sequence of execution\n",
    "workflow.set_entry_point(\"QwenNode1\") # Start with Llama3\n",
    "workflow.add_edge(\"QwenNode1\", \"QwenNode2\") # After Llama3, go to Mistral\n",
    "workflow.add_edge(\"QwenNode2\", \"QwenNode3\") # After Mistral, go to TinyLlama\n",
    "workflow.add_edge(\"QwenNode3\", END) # After TinyLlama, end the graph\n",
    "\n",
    "# Compile the graph\n",
    "app = workflow.compile()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "5193d0b4",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "---NODE 1: Llama3 Processing---\n"
     ]
    },
    {
     "data": {
      "text/markdown": [
       "Node 1 Qwen's take: <think>\n",
       "Okay, the user wants me to explain masked language modeling tasks in simple language, add a brief introduction, and start with \"Response 1:.\"\n",
       "\n",
       "First, I need to make sure I understand what masked language modeling is. From what I remember, it's a technique used in machine learning where the model is trained to understand and generate text that's similar to the input. But how to simplify that?\n",
       "\n",
       "The user mentioned \"masked language modeling task,\" so I should explain that. Maybe start with a simple example, like a chatbot that can understand and generate text. Then mention that the model is trained to understand the context, not just the words. Also, include that it's used in various fields like AI, natural language processing, etc.\n",
       "\n",
       "Wait, the user wants a brief introduction first. So maybe something like: \"In masked language modeling, the model learns to understand and generate text by being trained on a large dataset of text. This allows it to understand context and generate text that's similar to the input.\"\n",
       "\n",
       "I need to check if that's all. Make sure the response starts with \"Response 1:\" and is in simple language. Avoid technical jargon. Let me put it all together.\n",
       "</think>\n",
       "\n",
       "**Response 1:**  \n",
       "Masked language modeling is a technique used in machine learning where the model learns to understand and generate text by being trained on a large dataset of text. This allows it to understand context and generate text that's similar to the input. Itâ€™s used in various fields like AI, natural language processing, and language modeling to create text that mimics human speech.\n"
      ],
      "text/plain": [
       "<IPython.core.display.Markdown object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "=========================\n",
      "---NODE 2: Mistral Processing---\n"
     ]
    },
    {
     "data": {
      "text/markdown": [
       "Node 2 Qwen's take: <think>\n",
       "Okay, the user wants me to elaborate on \"masked language modeling task in simple language.\" They also mentioned considering previous output, which I did. Now, I need to make sure my response is simple and starts with \"Response 2:.\"\n",
       "\n",
       "First, I'll explain masked language modeling in a basic way. Maybe use an example like a chatbot that can understand and generate text. Then mention that the model learns by being trained on a large dataset. I should keep it straightforward and avoid any technical terms. Let me check if that covers all the points and starts with \"Response 2:\".\n",
       "</think>\n",
       "\n",
       "**Response 2:**  \n",
       "Masked language modeling is when a machine learning model learns to understand and generate text by being trained on a large dataset of text. This helps it understand context and generate text that's similar to the input. It's used in AI, language processing, and other fields to create text that mimics human speech.\n"
      ],
      "text/plain": [
       "<IPython.core.display.Markdown object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "=========================\n",
      "---NODE 3: TinyLlama Processing---\n"
     ]
    },
    {
     "data": {
      "text/markdown": [
       "Llama3's take: <think>\n",
       "Okay, the user wants me to summarize the main point of \"masked language modeling task in simple language\" after seeing the previous response. Let me check the previous response to make sure I'm on the right track.\n",
       "\n",
       "In the first response, I explained masked language modeling as a technique where a model learns to understand and generate text by being trained on a large dataset. The user wants a summary in simple language, so I need to rephrase that into a brief explanation. Let me make sure to mention that it's used in AI, natural language processing, etc., and that it helps with generating text similar to the input. I should start with \"Response 3:\" to match the previous structure. Let me put that together clearly.\n",
       "</think>\n",
       "\n"
      ],
      "text/plain": [
       "<IPython.core.display.Markdown object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "=========================\n"
     ]
    }
   ],
   "source": [
    "user_question = \"Explain the concept of masked language modeling task in simple language.\"\n",
    "for s in app.stream({\"question\": user_question, \"response\": \"\"}):\n",
    "    node_name = list(s.keys())[0]\n",
    "    display(Markdown(s[node_name][\"response\"]))\n",
    "    print(\"=\"*25)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "1738173b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "---NODE 1: Llama3 Processing---\n"
     ]
    },
    {
     "data": {
      "text/markdown": [
       "Node 1 Qwen's take: <think>\n",
       "Okay, the user wants me to explain masked language modeling tasks in simple language, add a brief introduction, and start with \"Response 1:.\"\n",
       "\n",
       "First, I need to make sure I understand what masked language modeling is. From what I remember, it's a technique used in machine learning where the model is trained to understand and generate text that's similar to the input. But how to simplify that?\n",
       "\n",
       "The user mentioned \"masked language modeling task,\" so I should explain that. Maybe start with a simple example, like a chatbot that can understand and generate text. Then mention that the model is trained to understand the context, not just the words. Also, include that it's used in various fields like AI, natural language processing, etc.\n",
       "\n",
       "Wait, the user wants a brief introduction first. So maybe something like: \"In masked language modeling, the model learns to understand and generate text by being trained on a large dataset of text. This allows it to understand context and generate text that's similar to the input.\"\n",
       "\n",
       "I need to check if that's all. Make sure the response starts with \"Response 1:\" and is in simple language. Avoid technical jargon. Let me put it all together.\n",
       "</think>\n",
       "\n",
       "**Response 1:**  \n",
       "Masked language modeling is a technique used in machine learning where the model learns to understand and generate text by being trained on a large dataset of text. This allows it to understand context and generate text that's similar to the input. Itâ€™s used in various fields like AI, natural language processing, and language modeling to create text that mimics human speech.\n"
      ],
      "text/plain": [
       "<IPython.core.display.Markdown object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "---\n",
      "---NODE 2: Mistral Processing---\n"
     ]
    },
    {
     "data": {
      "text/markdown": [
       "Node 2 Qwen's take: <think>\n",
       "Okay, the user wants me to elaborate on \"masked language modeling task in simple language.\" They also mentioned considering previous output, which I did. Now, I need to make sure my response is simple and starts with \"Response 2:.\"\n",
       "\n",
       "First, I'll explain masked language modeling in a basic way. Maybe use an example like a chatbot that can understand and generate text. Then mention that the model learns by being trained on a large dataset. I should keep it straightforward and avoid any technical terms. Let me check if that covers all the points and starts with \"Response 2:\".\n",
       "</think>\n",
       "\n",
       "**Response 2:**  \n",
       "Masked language modeling is when a machine learning model learns to understand and generate text by being trained on a large dataset of text. This helps it understand context and generate text that's similar to the input. It's used in AI, language processing, and other fields to create text that mimics human speech.\n"
      ],
      "text/plain": [
       "<IPython.core.display.Markdown object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "---\n",
      "---NODE 3: TinyLlama Processing---\n"
     ]
    },
    {
     "data": {
      "text/markdown": [
       "Llama3's take: <think>\n",
       "Okay, the user wants me to summarize the main point of \"masked language modeling task in simple language\" after seeing the previous response. Let me check the previous response to make sure I'm on the right track.\n",
       "\n",
       "In the first response, I explained masked language modeling as a technique where a model learns to understand and generate text by being trained on a large dataset. The user wants a summary in simple language, so I need to rephrase that into a brief explanation. Let me make sure to mention that it's used in AI, natural language processing, etc., and that it helps with generating text similar to the input. I should start with \"Response 3:\" to match the previous structure. Let me put that together clearly.\n",
       "</think>\n",
       "\n"
      ],
      "text/plain": [
       "<IPython.core.display.Markdown object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "---\n"
     ]
    }
   ],
   "source": [
    "for s in app.stream({\"question\": user_question, \"response\": \"\"}):\n",
    "    node_name = list(s.keys())[0]\n",
    "    #print(s[node_name][\"response\"])\n",
    "    display(Markdown(s[node_name][\"response\"]))\n",
    "    print(\"---\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "062883ed",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "llm_env",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.14"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
